{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Acne and Rosacea Photos', 'Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions', 'Atopic Dermatitis Photos', 'Bullous Disease Photos', 'Cellulitis Impetigo and other Bacterial Infections', 'Eczema Photos', 'Exanthems and Drug Eruptions', 'Hair Loss Photos Alopecia and other Hair Diseases', 'Herpes HPV and other STDs Photos', 'Light Diseases and Disorders of Pigmentation', 'Lupus and other Connective Tissue diseases', 'Melanoma Skin Cancer Nevi and Moles', 'Nail Fungus and other Nail Disease', 'Poison Ivy Photos and other Contact Dermatitis', 'Psoriasis pictures Lichen Planus and related diseases', 'Scabies Lyme Disease and other Infestations and Bites', 'Seborrheic Keratoses and other Benign Tumors', 'Tinea Ringworm Candidiasis and other Fungal Infections', 'Urticaria Hives', 'Vascular Tumors', 'Vasculitis Photos', 'Warts Molluscum and other Viral Infections']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# get the current working directory\n",
    "os.chdir(\"D:\\ML_Practice\\Skin Data\")\n",
    "cwd = (os.getcwd()+\"/MyData\")\n",
    "\n",
    "# list all files and directories in the current working directory\n",
    "files_and_directories = os.listdir(cwd)\n",
    "\n",
    "\n",
    "# filter the list to only include directories (i.e., exclude files)\n",
    "folder_names = [f for f in files_and_directories if os.path.isdir(os.path.join(cwd, f))]\n",
    "\n",
    "print(folder_names)  # prints a list of the directories in the current working directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image,ImageOps\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "X = []  # list to store the images\n",
    "y = []  # list to store the labels\n",
    "img_Size=64\n",
    "\n",
    "for i, folder_name in enumerate(folder_names):\n",
    "    # navigate to the folder\n",
    "    path = os.path.join(cwd, folder_name)\n",
    "    os.chdir(path)\n",
    "\n",
    "    # open all images in the folder\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith('.jpg'):\n",
    "            image = cv2.imread(file,cv2.IMREAD_GRAYSCALE)\n",
    "            image = cv2.resize(image,(img_Size,img_Size))\n",
    "            # you can do something with the image here, such as preprocessing it for neural network training\n",
    "            X.append(image)\n",
    "            y.append(i)  # append the label for the image (i.e., the index of the folder)\n",
    "\n",
    "# convert the lists to numpy arrays\n",
    "X = np.array(X).reshape(-1,img_Size,img_Size,1)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16,  5,  0, ..., 16, 21,  5])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=X/255\n",
    "from sklearn.utils import shuffle\n",
    "X_train,y_Train = shuffle(X,y)\n",
    "\n",
    "y_Train\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_Train,X_Test,y_Train,y_Test = train_test_split(X,y,test_size=0.1,shuffle=True)\n",
    "# print(y_Train,y_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14951"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Initialize the CNN\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first convolutional layer\n",
    "model.add(Conv2D(32, (3, 3), input_shape = (img_Size, img_Size, 1), activation = 'relu'))\n",
    "\n",
    "# Add a max pooling layer\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Add a second convolutional layer\n",
    "model.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "\n",
    "# Add a second max pooling layer\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Add a flattening layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add a fully connected layer\n",
    "model.add(Dense(units = 128, activation = 'relu'))\n",
    "\n",
    "# Add an output layer\n",
    "model.add(Dense(units = 22, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "121/121 [==============================] - 6s 48ms/step - loss: 2.9151 - accuracy: 0.1091\n",
      "Epoch 2/50\n",
      "121/121 [==============================] - 6s 47ms/step - loss: 2.8167 - accuracy: 0.1421\n",
      "Epoch 3/50\n",
      "121/121 [==============================] - 6s 48ms/step - loss: 2.7597 - accuracy: 0.1584\n",
      "Epoch 4/50\n",
      "121/121 [==============================] - 6s 52ms/step - loss: 2.6924 - accuracy: 0.1800\n",
      "Epoch 5/50\n",
      "121/121 [==============================] - 6s 50ms/step - loss: 2.6130 - accuracy: 0.2101\n",
      "Epoch 6/50\n",
      "121/121 [==============================] - 6s 50ms/step - loss: 2.5104 - accuracy: 0.2397\n",
      "Epoch 7/50\n",
      "121/121 [==============================] - 6s 51ms/step - loss: 2.3946 - accuracy: 0.2782\n",
      "Epoch 8/50\n",
      "121/121 [==============================] - 6s 50ms/step - loss: 2.2718 - accuracy: 0.3114\n",
      "Epoch 9/50\n",
      "121/121 [==============================] - 6s 51ms/step - loss: 2.1279 - accuracy: 0.3488\n",
      "Epoch 10/50\n",
      "121/121 [==============================] - 6s 50ms/step - loss: 1.9698 - accuracy: 0.4083\n",
      "Epoch 11/50\n",
      "121/121 [==============================] - 6s 50ms/step - loss: 1.8185 - accuracy: 0.4408\n",
      "Epoch 12/50\n",
      "121/121 [==============================] - 6s 50ms/step - loss: 1.6539 - accuracy: 0.5065\n",
      "Epoch 13/50\n",
      "121/121 [==============================] - 6s 50ms/step - loss: 1.4811 - accuracy: 0.5527\n",
      "Epoch 14/50\n",
      "121/121 [==============================] - 6s 51ms/step - loss: 1.2955 - accuracy: 0.6109\n",
      "Epoch 15/50\n",
      "121/121 [==============================] - 7s 56ms/step - loss: 1.1151 - accuracy: 0.6745\n",
      "Epoch 16/50\n",
      "121/121 [==============================] - 7s 57ms/step - loss: 0.9640 - accuracy: 0.7244\n",
      "Epoch 17/50\n",
      "121/121 [==============================] - 6s 48ms/step - loss: 0.8104 - accuracy: 0.7686\n",
      "Epoch 18/50\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.6542 - accuracy: 0.8192\n",
      "Epoch 19/50\n",
      "121/121 [==============================] - 6s 48ms/step - loss: 0.5347 - accuracy: 0.8566\n",
      "Epoch 20/50\n",
      "121/121 [==============================] - 6s 48ms/step - loss: 0.4461 - accuracy: 0.8906\n",
      "Epoch 21/50\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.3498 - accuracy: 0.9203\n",
      "Epoch 22/50\n",
      "121/121 [==============================] - 6s 50ms/step - loss: 0.2992 - accuracy: 0.9338\n",
      "Epoch 23/50\n",
      "121/121 [==============================] - 7s 59ms/step - loss: 0.2659 - accuracy: 0.9442\n",
      "Epoch 24/50\n",
      "121/121 [==============================] - 7s 56ms/step - loss: 0.2228 - accuracy: 0.9564\n",
      "Epoch 25/50\n",
      "121/121 [==============================] - 6s 54ms/step - loss: 0.1747 - accuracy: 0.9696\n",
      "Epoch 26/50\n",
      "121/121 [==============================] - 7s 55ms/step - loss: 0.1394 - accuracy: 0.9758\n",
      "Epoch 27/50\n",
      "121/121 [==============================] - 6s 54ms/step - loss: 0.1216 - accuracy: 0.9813\n",
      "Epoch 28/50\n",
      "121/121 [==============================] - 7s 54ms/step - loss: 0.0997 - accuracy: 0.9847\n",
      "Epoch 29/50\n",
      "121/121 [==============================] - 6s 50ms/step - loss: 0.0988 - accuracy: 0.9865\n",
      "Epoch 30/50\n",
      "121/121 [==============================] - 6s 51ms/step - loss: 0.0859 - accuracy: 0.9860\n",
      "Epoch 31/50\n",
      "121/121 [==============================] - 6s 50ms/step - loss: 0.0797 - accuracy: 0.9904\n",
      "Epoch 32/50\n",
      "121/121 [==============================] - 6s 52ms/step - loss: 0.0847 - accuracy: 0.9855\n",
      "Epoch 33/50\n",
      "121/121 [==============================] - 7s 54ms/step - loss: 0.0768 - accuracy: 0.9881\n",
      "Epoch 34/50\n",
      "121/121 [==============================] - 6s 53ms/step - loss: 0.0557 - accuracy: 0.9909\n",
      "Epoch 35/50\n",
      "121/121 [==============================] - 6s 50ms/step - loss: 0.0722 - accuracy: 0.9888\n",
      "Epoch 36/50\n",
      "121/121 [==============================] - 6s 51ms/step - loss: 0.0569 - accuracy: 0.9894\n",
      "Epoch 37/50\n",
      "121/121 [==============================] - 6s 51ms/step - loss: 0.0777 - accuracy: 0.9860\n",
      "Epoch 38/50\n",
      "121/121 [==============================] - 6s 52ms/step - loss: 0.0853 - accuracy: 0.9818\n",
      "Epoch 39/50\n",
      "121/121 [==============================] - 6s 51ms/step - loss: 0.0927 - accuracy: 0.9808\n",
      "Epoch 40/50\n",
      "121/121 [==============================] - 6s 50ms/step - loss: 0.1565 - accuracy: 0.9631\n",
      "Epoch 41/50\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0952 - accuracy: 0.9792\n",
      "Epoch 42/50\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0848 - accuracy: 0.9805\n",
      "Epoch 43/50\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0973 - accuracy: 0.9748\n",
      "Epoch 44/50\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0613 - accuracy: 0.9865\n",
      "Epoch 45/50\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0588 - accuracy: 0.9875\n",
      "Epoch 46/50\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0521 - accuracy: 0.9888\n",
      "Epoch 47/50\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.0537 - accuracy: 0.9883\n",
      "Epoch 48/50\n",
      "121/121 [==============================] - 6s 51ms/step - loss: 0.0423 - accuracy: 0.9901\n",
      "Epoch 49/50\n",
      "121/121 [==============================] - 6s 52ms/step - loss: 0.0494 - accuracy: 0.9899\n",
      "Epoch 50/50\n",
      "121/121 [==============================] - 6s 52ms/step - loss: 0.0471 - accuracy: 0.9894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x242e0ea2e30>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_Train,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Acne and Rosacea Photos', 'Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions', 'Atopic Dermatitis Photos', 'Bullous Disease Photos', 'Cellulitis Impetigo and other Bacterial Infections', 'Eczema Photos', 'Exanthems and Drug Eruptions', 'Hair Loss Photos Alopecia and other Hair Diseases', 'Herpes HPV and other STDs Photos', 'Light Diseases and Disorders of Pigmentation', 'Lupus and other Connective Tissue diseases', 'Melanoma Skin Cancer Nevi and Moles', 'Nail Fungus and other Nail Disease', 'Poison Ivy Photos and other Contact Dermatitis', 'Psoriasis pictures Lichen Planus and related diseases', 'Scabies Lyme Disease and other Infestations and Bites', 'Seborrheic Keratoses and other Benign Tumors', 'Tinea Ringworm Candidiasis and other Fungal Infections', 'Urticaria Hives', 'Vascular Tumors', 'Vasculitis Photos', 'Warts Molluscum and other Viral Infections']\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"D:\\ML_Practice\\Skin Data\")\n",
    "\n",
    "cwds=os.getcwd()+\"/test\"\n",
    "\n",
    "# list all files and directories in the current working directory\n",
    "files_and_directories_test = os.listdir(cwds)\n",
    "\n",
    "# filter the list to only include directories (i.e., exclude files)\n",
    "folder_names_test = [f for f in files_and_directories_test if os.path.isdir(os.path.join(cwds, f))]\n",
    "\n",
    "print(folder_names_test)  # prints a list of the directories in the current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Test = []  # list to store the images\n",
    "y_Test = []  # list to store the labels\n",
    "img_Size=64\n",
    "\n",
    "for i, folder_name in enumerate(folder_names):\n",
    "    # navigate to the folder\n",
    "    path = os.path.join(cwds, folder_name)\n",
    "    os.chdir(path)\n",
    "\n",
    "    # open all images in the folder\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith('.jpg'):\n",
    "            image = cv2.imread(file,cv2.IMREAD_GRAYSCALE)\n",
    "            image = cv2.resize(image,(img_Size,img_Size))\n",
    "            # you can do something with the image here, such as preprocessing it for neural network training\n",
    "            X_Test.append(image)\n",
    "            y_Test.append(i)  # append the label for the image (i.e., the index of the folder)\n",
    "\n",
    "# convert the lists to numpy arrays\n",
    "X_Test = np.array(X_Test).reshape(-1,img_Size,img_Size,1)\n",
    "y_Test = np.array(y_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_Test)\n",
    "X_Test = X_Test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 2s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "predicted=model.predict(X_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.8819274e-01, 1.0562189e-06, 8.9175272e-05, ..., 5.5360946e-05,\n",
       "        6.8572740e-07, 2.2761228e-03],\n",
       "       [9.9996793e-01, 4.6823998e-14, 3.1813122e-11, ..., 1.1535463e-07,\n",
       "        1.6524945e-10, 2.6103399e-08],\n",
       "       [9.3753809e-01, 4.5402849e-08, 1.0529830e-06, ..., 4.2752360e-04,\n",
       "        1.5096862e-07, 1.5630880e-05],\n",
       "       ...,\n",
       "       [4.0905683e-09, 7.8799218e-05, 1.9212159e-03, ..., 4.0186041e-08,\n",
       "        1.2537981e-05, 9.5526916e-01],\n",
       "       [5.7281729e-13, 3.8422789e-11, 1.3978309e-03, ..., 3.8023218e-10,\n",
       "        1.2214567e-12, 9.9854761e-01],\n",
       "       [2.0211090e-04, 5.9657843e-05, 5.4673816e-04, ..., 1.5192104e-03,\n",
       "        2.1755133e-07, 9.7610384e-01]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Test Data = 3850\n",
      "Predicted Right = 3819\n",
      "Predicted Wrong = 31\n"
     ]
    }
   ],
   "source": [
    "predicted_result =[]\n",
    "predicted_right=0\n",
    "predicted_wrong=0\n",
    "for i in range(len(predicted)):\n",
    "    for j in range(22):\n",
    "        if max(predicted[i])==predicted[i][j]:\n",
    "            if j == y_Test[i]:\n",
    "                predicted_right+=1\n",
    "            else:\n",
    "                predicted_wrong+=1    \n",
    "            predicted_result.append(j)\n",
    "print(\"Total Test Data = {}\\nPredicted Right = {}\\nPredicted Wrong = {}\".format(len(predicted),predicted_right,predicted_wrong))               \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 2s 16ms/step - loss: 0.0437 - accuracy: 0.9919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04369794577360153, 0.9919480681419373]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_Test,y_Test)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99198752291008"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "f1_score = metrics.f1_score(y_Test, predicted_result,average=\"weighted\")\n",
    "f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(\"D:\\ML_Practice\\Skin Data\")\n",
    "model.save('my_model.h5')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468/468 [==============================] - 5s 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.90683556e-01, 1.86356761e-08, 2.28861245e-06, ...,\n",
       "        1.19012265e-11, 9.69581748e-09, 2.97284988e-03],\n",
       "       [9.81785178e-01, 2.13284045e-03, 2.90340640e-10, ...,\n",
       "        2.25399802e-07, 2.88669777e-13, 2.02140859e-06],\n",
       "       [8.44561279e-01, 1.80824936e-04, 2.53921412e-10, ...,\n",
       "        2.47138061e-08, 2.34923618e-06, 1.45534247e-01],\n",
       "       ...,\n",
       "       [1.51833677e-21, 1.21635883e-24, 3.35227814e-17, ...,\n",
       "        3.09116580e-03, 3.22190694e-20, 9.71621633e-01],\n",
       "       [8.57486478e-12, 2.90868774e-09, 1.91548595e-21, ...,\n",
       "        3.82450125e-08, 2.25410389e-07, 9.99743998e-01],\n",
       "       [2.46896111e-14, 2.45407722e-11, 4.93291871e-17, ...,\n",
       "        1.20886618e-13, 7.58479390e-12, 9.99999881e-01]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e053143ccb14469edfd4999e26ffdd78b50f7895b1320475e541b6672f2f3ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
